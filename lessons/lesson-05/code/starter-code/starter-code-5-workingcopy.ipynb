{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### INDEED #####\n",
    "\n",
    "# a job posting website (as well as resume hosting)\n",
    "# scrape some (or A LOT) of job postings from indeed for the job \"data scientist\"\n",
    "# Plan of Action:\n",
    "# 1. Figure out the url for getting the summaries (by doing it yourself!)\n",
    "# 2. Scrape the summary\n",
    "# 3. Figure out how to change the page by changing the URL (hint, click the next page button and see how the url changes)\n",
    "# 4. BONUS: count the most used words in the sumaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import re #regex for regular expressions\n",
    "from bs4 import BeautifulSoup\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# r = requests.get('http://finance.google.com/finance?q='+symbol) # the url of the google finance page goes in here\n",
    "pages = ['http://www.indeed.com/q-data-scientist-jobs.html','http://www.indeed.com/jobs?q=data+scientist&start=10&pp=','http://www.indeed.com/jobs?q=data+scientist&start=20&pp=','http://www.indeed.com/jobs?q=data+scientist&start=30&pp=','http://www.indeed.com/jobs?q=data+scientist&start=40&pp=']\n",
    "r = requests.get('http://www.indeed.com/q-data-scientist-jobs.html')\n",
    "b = BeautifulSoup(r.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### UFO ######\n",
    "\n",
    "# SCRAPE ALL SIGHTINGS in 2015\n",
    "# Plan of action\n",
    "# 1. Figure out the pattern to get a certain year and month from nuforc\n",
    "# 2. Scrape each sightings\n",
    "# 3. Make a dataframe out of it\n",
    "# 4. make a day column\n",
    "# 5. graph each day in 2015 and see which day had the most! (Is it July 4th?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### TWITTER ######\n",
    "\n",
    "# Create a dataframe where each row is a tweet that uses any tag you choose!\n",
    "# include a column for date, text, user handle, user name, and user image\n",
    "# You can use the normal query method and not stream for this!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
